"""
DecideNode - å†³ç­–èŠ‚ç‚¹ (æ ¸å¿ƒï¼Œå«è®¡åˆ’é‡è¯»)

èŒè´£:
- å†³ç­–å‰é‡è¯»è®¡åˆ’æ–‡ä»¶ (Manus-style æ³¨æ„åŠ›æ“çºµ)
- åˆ†æä»»åŠ¡å’Œä¸Šä¸‹æ–‡
- å†³å®šä¸‹ä¸€æ­¥: tool / think / answer
"""

import re
from pocketflow import AsyncNode

from utils import call_llm_async

from .base import (
    Action,
    parse_yaml_response,
    CONTEXT_WINDOW_SIZE,
    YAML_PARSE_MAX_RETRIES,
    YAML_FORMAT_REMINDER,
)
from .planning_utils import (
    PLAN_FILE,
    FINDINGS_FILE,
    PROGRESS_FILE,
    read_planning_file,
    get_plan_completion_status,
)

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from logging_config import log_decision


class DecideNode(AsyncNode):
    """
    å†³ç­–èŠ‚ç‚¹ (æ ¸å¿ƒï¼Œå«è®¡åˆ’é‡è¯»)

    èŒè´£:
    - å†³ç­–å‰é‡è¯»è®¡åˆ’æ–‡ä»¶ (Manus-style æ³¨æ„åŠ›æ“çºµ)
    - åˆ†æä»»åŠ¡å’Œä¸Šä¸‹æ–‡
    - å†³å®šä¸‹ä¸€æ­¥: tool / think / answer
    """

    async def prep_async(self, shared):
        """å‡†å¤‡å†³ç­–æ‰€éœ€çš„ä¸Šä¸‹æ–‡ï¼ˆå«è®¡åˆ’é‡è¯»ï¼‰"""
        task = shared.get("current_task", "")
        context = shared.get("context", "")
        step_count = shared.get("step_count", 0)
        max_steps = shared.get("max_steps", 10)
        retrieved_memory = shared.get("retrieved_memory", "")
        has_plan = shared.get("has_plan", False)

        # ========================================
        # æ–¹æ¡ˆ3: è½¯é™åˆ¶ + å»¶é•¿æœºåˆ¶
        # ========================================
        if step_count >= max_steps:
            extension_count = shared.get("extension_count", 0)
            max_extensions = 2  # æœ€å¤šå»¶é•¿2æ¬¡

            if extension_count >= max_extensions:
                print(f"   [Decide] âš ï¸  Maximum extensions reached ({max_extensions}), forcing answer...")
                return {"force_answer": True, "task": task, "context": context}

            # è¯¢é—® LLM æ˜¯å¦éœ€è¦å»¶é•¿
            print(f"   [Decide] ğŸ“Š Step limit reached ({step_count}/{max_steps}), checking if extension needed...")
            extension_decision = await self._ask_llm_extension(shared, step_count, max_steps, extension_count, max_extensions)

            if extension_decision == "continue":
                extension_amount = 10
                shared["max_steps"] = max_steps + extension_amount
                shared["extension_count"] = extension_count + 1
                print(f"   [Decide] âœ… Extended by {extension_amount} steps, new limit: {shared['max_steps']} (extensions used: {shared['extension_count']}/{max_extensions})")
                # ç»§ç»­æ­£å¸¸æµç¨‹ï¼Œä¸å¼ºåˆ¶å›ç­”
            else:
                print(f"   [Decide] ğŸ LLM chose to wrap up, forcing final answer...")
                return {"force_answer": True, "task": task, "context": context}

        # ========================================
        # Manus-style: å†³ç­–å‰é‡è¯»è®¡åˆ’ (æ³¨æ„åŠ›æ“çºµ)
        # ========================================
        plan_context = ""
        if has_plan:
            plan_content = read_planning_file(PLAN_FILE)
            if plan_content:
                # æå–å…³é”®éƒ¨åˆ†ï¼šç›®æ ‡ã€å½“å‰é˜¶æ®µã€è¿›åº¦
                plan_summary = self._extract_plan_summary(plan_content)
                if plan_summary:
                    plan_context = f"### Current Plan Status\n{plan_summary}\n\n"
                    print(f"   [Decide] Re-read plan for attention focus")

        # ========================================
        # è¡Œä¸ºè§„åˆ™æ³¨å…¥ï¼šç¡®ä¿ LLM éµå¾ªå…¨å±€è§„åˆ™
        # ========================================
        behavior_rules = shared.get("behavior_rules", "")
        if not behavior_rules:
            try:
                from rules_engine import load_rules
                behavior_rules = load_rules()
                if behavior_rules:
                    shared["behavior_rules"] = behavior_rules
                    print(f"   [Decide] Behavior rules loaded ({len(behavior_rules)} chars)")
            except Exception as e:
                print(f"   [WARN] Failed to load behavior rules: {e}")

        # ========================================
        # ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼šåªä¿ç•™æœ€è¿‘ N æ­¥æ“ä½œ
        # ========================================
        trimmed_context = self._trim_context(context, CONTEXT_WINDOW_SIZE)
        if trimmed_context != context:
            print(f"   [Decide] Context trimmed to last {CONTEXT_WINDOW_SIZE} steps")

        # ========================================
        # æ–¹æ¡ˆ1: ç”Ÿæˆå‰©ä½™æ­¥æ•°è­¦å‘Šä¿¡æ¯
        # ========================================
        remaining_steps = max_steps - step_count
        steps_warning = self._get_step_warning(step_count, max_steps, remaining_steps)

        # æ„å»ºä¸Šä¸‹æ–‡ï¼ŒåŒ…å«æ£€ç´¢åˆ°çš„è®°å¿†
        full_context = ""

        # æ­¥æ•°è­¦å‘Šæ”¾åœ¨æœ€å‰é¢ï¼ˆç¡®ä¿ LLM æ³¨æ„åˆ°ï¼‰
        if steps_warning:
            full_context += steps_warning + "\n"

        # è®¡åˆ’æ”¾åœ¨ç¬¬äºŒä½ï¼ˆæ¨å…¥è¿‘æœŸæ³¨æ„åŠ›ï¼‰
        if plan_context:
            full_context += plan_context

        # è¡Œä¸ºè§„åˆ™æ”¾åœ¨ç¬¬ä¸‰ä½ï¼ˆç¡®ä¿ LLM éµå¾ªè§„åˆ™ï¼‰
        if behavior_rules:
            # åªæå–å…³é”®è§„åˆ™ï¼Œé¿å… token è¿‡å¤§
            rules_summary = self._extract_key_rules(behavior_rules)
            if rules_summary:
                full_context += f"### Behavior Rules (MUST FOLLOW)\n{rules_summary}\n\n"

        if retrieved_memory:
            full_context += f"### Related Past Conversations\n{retrieved_memory}\n\n"
        if trimmed_context:
            full_context += f"### Current Session Info\n{trimmed_context}"

        # æ„å»ºæ›´æ¸…æ™°çš„å†³ç­–æç¤º
        if full_context:
            user_msg = f"""Current Task: {task}

Collected Information:
{full_context}

---
Based on the above, decide next step:
- If enough info to answer, use action: answer
- If need more data, use action: tool
- If need analysis, use action: think

Reply in YAML format."""
        else:
            user_msg = f"""Current Task: {task}

{steps_warning}

No information collected yet.

Decide first action (usually call a tool).
Reply in YAML format."""

        messages = [
            {"role": "system", "content": shared.get("system_prompt", "")},
            {"role": "user", "content": user_msg}
        ]

        # ========================================
        # è°ƒè¯•æ—¥å¿—ï¼šè¿½è¸ªtokenæ¶ˆè€—
        # ========================================
        def estimate_tokens(text: str) -> int:
            """ç²—ç•¥ä¼°ç®—tokenæ•°ï¼ˆä¸­æ–‡1å­—â‰ˆ1.5tokenï¼Œè‹±æ–‡1è¯â‰ˆ1.3tokenï¼‰"""
            chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
            english_words = len(text.split()) - chinese_chars
            return int(chinese_chars * 1.5 + english_words * 1.3)

        system_tokens = estimate_tokens(messages[0]["content"])
        user_tokens = estimate_tokens(messages[1]["content"])
        total_tokens = system_tokens + user_tokens

        print(f"   [Decide] Token estimation:")
        print(f"      System prompt: ~{system_tokens} tokens")
        print(f"      User message: ~{user_tokens} tokens")
        if plan_context:
            plan_tokens = estimate_tokens(plan_context)
            print(f"         - Plan context: ~{plan_tokens} tokens")
        if retrieved_memory:
            memory_tokens = estimate_tokens(retrieved_memory)
            print(f"         - Retrieved memory: ~{memory_tokens} tokens")
        if trimmed_context:
            context_tokens = estimate_tokens(trimmed_context)
            sections_count = len(trimmed_context.split("\n\n###"))
            print(f"         - Current context: ~{context_tokens} tokens ({sections_count} sections)")
        print(f"      TOTAL: ~{total_tokens} tokens")

        # è­¦å‘Šï¼šå¦‚æœé¢„ä¼°è¶…è¿‡50ä¸‡tokensï¼Œå¾ˆå¯èƒ½æœ‰é—®é¢˜
        if total_tokens > 500000:
            print(f"      âš ï¸  WARNING: Estimated tokens ({total_tokens}) exceeds 500K!")
            print(f"      âš ï¸  Context length: {len(context)} chars")
            print(f"      âš ï¸  Trimmed context length: {len(trimmed_context)} chars")

        shared["step_count"] = step_count + 1

        return {"messages": messages, "force_answer": False, "task": task, "context": context}

    def _trim_context(self, context: str, window_size: int) -> str:
        """
        ä¿®å‰ªä¸Šä¸‹æ–‡ï¼Œåªä¿ç•™æœ€è¿‘ N æ­¥çš„æ“ä½œè®°å½•

        Args:
            context: å®Œæ•´çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
            window_size: ä¿ç•™çš„æ­¥éª¤æ•°é‡

        Returns:
            ä¿®å‰ªåçš„ä¸Šä¸‹æ–‡
        """
        if not context:
            return ""

        # æŒ‰æ“ä½œåˆ†æ®µï¼ˆæ¯ä¸ª ### æ ‡è®°ä¸€æ¬¡æ“ä½œï¼‰
        sections = context.split("\n\n###")

        if len(sections) <= window_size:
            return context

        # åªä¿ç•™æœ€å window_size ä¸ªæ“ä½œ
        recent_sections = sections[-window_size:]

        # é‡æ–°ç»„åˆï¼Œç¡®ä¿é¦–ä¸ªæ®µè½æœ‰ ### å‰ç¼€
        result = "###".join(recent_sections)
        if not result.startswith("###"):
            result = "###" + result

        return result

    def _extract_plan_summary(self, plan_content: str) -> str:
        """
        ä»è®¡åˆ’æ–‡ä»¶ä¸­æå–å…³é”®æ‘˜è¦ï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å«findingså’Œprogressï¼‰

        æå–å†…å®¹ï¼š
        1. task_plan.md: ç›®æ ‡ã€é˜¶æ®µã€é”™è¯¯
        2. findings.md: æœ€è¿‘3æ¡å…³é”®å‘ç°
        3. progress.md: æœ€è¿‘5æ­¥æ“ä½œæ‘˜è¦
        """
        summary_parts = []

        # ========================================
        # Part 1: task_plan.md æ ¸å¿ƒä¿¡æ¯
        # ========================================
        # æå–ç›®æ ‡
        goal_match = re.search(r"## Goal\n(.+?)(?=\n##|\Z)", plan_content, re.DOTALL)
        if goal_match:
            goal = goal_match.group(1).strip()[:200]
            summary_parts.append(f"**Goal**: {goal}")

        # æå–å½“å‰é˜¶æ®µ
        phase_match = re.search(r"## Current Phase\n(.+?)(?=\n##|\Z)", plan_content, re.DOTALL)
        if phase_match:
            phase = phase_match.group(1).strip()
            summary_parts.append(f"**Current Phase**: {phase}")

        # æå–å®ŒæˆçŠ¶æ€
        completed, total, uncompleted = get_plan_completion_status()
        if total > 0:
            summary_parts.append(f"**Progress**: {completed}/{total} phases completed")
            if uncompleted and len(uncompleted) > 0:
                next_phase = uncompleted[0] if uncompleted else ""
                summary_parts.append(f"**Next**: {next_phase}")

        # æå–æœ€è¿‘é”™è¯¯ï¼ˆå¸®åŠ©é¿å…é‡å¤ï¼‰
        if "## Errors Encountered" in plan_content:
            errors_section = plan_content.split("## Errors Encountered")[1].split("\n##")[0]
            error_lines = [l.strip() for l in errors_section.split("\n") if l.strip().startswith("-")]
            if error_lines:
                recent_errors = error_lines[-2:]  # æœ€è¿‘2ä¸ªé”™è¯¯
                summary_parts.append(f"**Recent Errors**: {'; '.join(recent_errors)}")

        # ========================================
        # Part 2: findings.md å…³é”®å‘ç°ï¼ˆä¼˜å…ˆä¿ç•™é«˜ä¼˜å…ˆçº§ï¼‰
        # ========================================
        findings_content = read_planning_file(FINDINGS_FILE)
        if findings_content:
            # æå–æ‰€æœ‰å‘ç°æ¡ç›®ï¼ˆåŒ…å«ä¼˜å…ˆçº§æ ‡ç­¾ï¼‰
            findings_entries = re.findall(
                r"### \[([^\]]+)\] (\[(?:CRITICAL|IMPORTANT)\] )?(.+?)\n\*\*Finding\*\*:\n(.+?)(?=\n\*\*Implications|### |\Z)",
                findings_content,
                re.DOTALL
            )
            if findings_entries:
                # åˆ†ç¦»é«˜ä¼˜å…ˆçº§å’Œæ™®é€šå‘ç°
                critical_findings = []
                important_findings = []
                normal_findings = []

                for timestamp, priority_tag, title, finding in findings_entries:
                    finding_short = finding.strip()[:200]
                    entry = f"  [{timestamp}] {priority_tag or ''}{title}: {finding_short}"

                    if priority_tag and "CRITICAL" in priority_tag:
                        critical_findings.append(entry)
                    elif priority_tag and "IMPORTANT" in priority_tag:
                        important_findings.append(entry)
                    else:
                        normal_findings.append(entry)

                # ç»„åˆï¼šæ‰€æœ‰ CRITICAL + æœ€è¿‘2æ¡ IMPORTANT + æœ€è¿‘2æ¡æ™®é€š
                findings_summary = []
                findings_summary.extend(critical_findings)  # ä¿ç•™æ‰€æœ‰ CRITICAL
                findings_summary.extend(important_findings[-2:])  # æœ€è¿‘2æ¡ IMPORTANT
                findings_summary.extend(normal_findings[-2:])  # æœ€è¿‘2æ¡æ™®é€š

                # é™åˆ¶æ€»æ•°é˜²æ­¢è¿‡é•¿
                findings_summary = findings_summary[:6]

                if findings_summary:
                    summary_parts.append(f"**Key Findings**:\n" + "\n".join(findings_summary))

        # ========================================
        # Part 3: progress.md æœ€è¿‘æ“ä½œ
        # ========================================
        progress_content = read_planning_file(PROGRESS_FILE)
        if progress_content:
            # æå–æœ€è¿‘5æ¡æ“ä½œè®°å½•
            progress_entries = re.findall(
                r"### \[([^\]]+)\] (.+?)\n- (.+?)(?=\n### |\Z)",
                progress_content,
                re.DOTALL
            )
            if progress_entries:
                recent_progress = progress_entries[-5:]  # æœ€è¿‘5æ¡
                progress_summary = []
                for timestamp, action_type, description in recent_progress:
                    # æ¸…ç†æè¿°ï¼ˆç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œï¼‰
                    desc_clean = " ".join(description.split())[:150]
                    progress_summary.append(f"  [{timestamp}] {action_type}: {desc_clean}")

                if progress_summary:
                    summary_parts.append(f"**Recent Actions**:\n" + "\n".join(progress_summary))

        return "\n".join(summary_parts) if summary_parts else ""

    def _extract_key_rules(self, rules: str, max_length: int = 2000) -> str:
        """
        ä»å®Œæ•´è§„åˆ™ä¸­æå–å…³é”®è§„åˆ™ï¼ˆé¿å… token è¿‡å¤§ï¼‰

        Args:
            rules: å®Œæ•´è§„åˆ™æ–‡æœ¬
            max_length: æœ€å¤§å­—ç¬¦æ•°

        Returns:
            ç²¾ç®€åçš„è§„åˆ™æ‘˜è¦
        """
        if not rules:
            return ""

        # æå– G-11 (Mojiå¤©æ°”) ç­‰å·¥å…·ç›¸å…³è§„åˆ™
        key_rules = []

        # æŸ¥æ‰¾æ‰€æœ‰ G-XX è§„åˆ™æ ‡é¢˜å’Œå†…å®¹
        rule_pattern = r"### (G-\d+): (.+?)\n(.+?)(?=\n### G-|\n---\n\*\*è§„åˆ™æ–‡ä»¶ç»“æŸ|$)"
        matches = re.findall(rule_pattern, rules, re.DOTALL)

        for rule_id, rule_title, rule_content in matches:
            # ä¼˜å…ˆæå–å·¥å…·ç›¸å…³è§„åˆ™ (G-05, G-11 ç­‰)
            if any(keyword in rule_title.lower() for keyword in ['å·¥å…·', 'tool', 'moji', 'å¤©æ°”']):
                # æˆªå–è§„åˆ™å†…å®¹çš„å‰500å­—ç¬¦
                content_short = rule_content.strip()[:500]
                if len(rule_content.strip()) > 500:
                    content_short += "..."
                key_rules.append(f"**{rule_id}: {rule_title}**\n{content_short}")

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å·¥å…·è§„åˆ™ï¼Œè¿”å›å‰ max_length å­—ç¬¦
        if not key_rules:
            return rules[:max_length] + ("..." if len(rules) > max_length else "")

        result = "\n\n".join(key_rules)
        return result[:max_length] + ("..." if len(result) > max_length else "")

    def _get_step_warning(self, step_count: int, max_steps: int, remaining_steps: int) -> str:
        """
        ç”Ÿæˆåˆ†çº§æ­¥æ•°è­¦å‘Šä¿¡æ¯ï¼ˆæ–¹æ¡ˆ1ï¼‰

        Args:
            step_count: å½“å‰æ­¥æ•°
            max_steps: æœ€å¤§æ­¥æ•°
            remaining_steps: å‰©ä½™æ­¥æ•°

        Returns:
            æ ¼å¼åŒ–çš„è­¦å‘Šä¿¡æ¯
        """
        progress_pct = (step_count / max_steps * 100) if max_steps > 0 else 0

        if remaining_steps <= 3:
            return f"""ğŸš¨ **CRITICAL**: Only {remaining_steps} steps remaining! Must provide answer very soon!
Progress: Step {step_count}/{max_steps} ({progress_pct:.0f}% used)
"""
        elif remaining_steps <= 8:
            return f"""âš ï¸ **WARNING**: {remaining_steps} steps remaining. Please start wrapping up your analysis.
Progress: Step {step_count}/{max_steps} ({progress_pct:.0f}% used)
"""
        elif remaining_steps <= 15:
            return f"""ğŸ“Š **Notice**: {remaining_steps} steps remaining. Plan your remaining actions carefully.
Progress: Step {step_count}/{max_steps} ({progress_pct:.0f}% used)
"""
        else:
            return f"ğŸ“Š Progress: Step {step_count}/{max_steps} ({remaining_steps} steps remaining)"

    async def _ask_llm_extension(
        self,
        shared: dict,
        step_count: int,
        max_steps: int,
        extension_count: int,
        max_extensions: int
    ) -> str:
        """
        è¯¢é—® LLM æ˜¯å¦éœ€è¦å»¶é•¿æ­¥æ•°é™åˆ¶ï¼ˆæ–¹æ¡ˆ3ï¼‰

        Args:
            shared: å…±äº«çŠ¶æ€
            step_count: å½“å‰æ­¥æ•°
            max_steps: å½“å‰æœ€å¤§æ­¥æ•°
            extension_count: å·²ä½¿ç”¨çš„å»¶é•¿æ¬¡æ•°
            max_extensions: æœ€å¤§å»¶é•¿æ¬¡æ•°

        Returns:
            "continue" æˆ– "answer"
        """
        task = shared.get("current_task", "")
        context = shared.get("context", "")

        # æ„å»ºå»¶é•¿è¯·æ±‚çš„ prompt
        extension_prompt = f"""You've reached the step limit ({step_count}/{max_steps} steps used).

**Current Task**: {task}

**Progress Summary**:
{context[-1000:] if len(context) > 1000 else context}

**Extension Options**:
- You have {max_extensions - extension_count} extension(s) remaining
- Each extension grants 10 additional steps
- Maximum {max_extensions} extensions total

**Decision Required**:
Choose ONE of the following:
1. **continue** - Request extension to continue working (recommended if task is not complete)
2. **answer** - Provide final answer now with current information

**Reply Format**:
```yaml
decision: continue  # or "answer"
reason: "Brief explanation of your choice"
```

Make your decision:"""

        messages = [
            {"role": "system", "content": "You are a task completion evaluator. Decide whether to continue or wrap up based on task completion status."},
            {"role": "user", "content": extension_prompt}
        ]

        try:
            response = await call_llm_async(messages)

            # è§£æ YAML å“åº”
            import yaml
            parsed = yaml.safe_load(response)

            if isinstance(parsed, dict) and "decision" in parsed:
                decision = parsed["decision"].lower().strip()
                reason = parsed.get("reason", "No reason provided")

                print(f"   [Decide] Extension decision: {decision}")
                print(f"   [Decide] Reason: {reason}")

                if decision in ["continue", "answer"]:
                    return decision
                else:
                    print(f"   [Decide] Invalid decision '{decision}', defaulting to 'answer'")
                    return "answer"
            else:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„å…³é”®è¯åŒ¹é…
                response_lower = response.lower()
                if "continue" in response_lower and "answer" not in response_lower:
                    print(f"   [Decide] Keyword match: continue")
                    return "continue"
                else:
                    print(f"   [Decide] Keyword match or default: answer")
                    return "answer"

        except Exception as e:
            print(f"   [Decide] Extension request failed: {e}, defaulting to 'answer'")
            return "answer"

    async def exec_async(self, prep_res):
        """è°ƒç”¨ LLM è¿›è¡Œå†³ç­–ï¼ˆå« YAML è§£æé‡è¯•æœºåˆ¶ï¼‰"""
        if prep_res.get("force_answer"):
            # å¼ºåˆ¶å›ç­”
            return {
                "action": Action.ANSWER,
                "reason": "Max steps reached, force answer",
                "answer": "Based on collected information..."
            }

        messages = prep_res["messages"]
        last_response = None

        # é‡è¯•å¾ªç¯
        for attempt in range(YAML_PARSE_MAX_RETRIES + 1):
            try:
                response = await call_llm_async(messages)
                last_response = response
            except Exception as e:
                print(f"   [ERROR] LLM call failed: {e}")
                return {
                    "action": Action.ANSWER,
                    "reason": f"LLM call failed: {e}",
                    "answer": "Sorry, AI service temporarily unavailable."
                }

            # è§£æ YAML
            try:
                return parse_yaml_response(response)
            except ValueError as e:
                if attempt < YAML_PARSE_MAX_RETRIES:
                    # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œå‘é€æ ¼å¼æé†’
                    print(f"   [WARN] YAML parse failed (attempt {attempt + 1}), retrying...")
                    messages = messages + [
                        {"role": "assistant", "content": response},
                        {"role": "user", "content": YAML_FORMAT_REMINDER}
                    ]
                else:
                    # é‡è¯•ç”¨å°½ï¼Œå›é€€åˆ°ç›´æ¥å›ç­”
                    print(f"   [WARN] YAML parse failed after {YAML_PARSE_MAX_RETRIES + 1} attempts")
                    return {
                        "action": Action.ANSWER,
                        "reason": str(e),
                        "answer": last_response if last_response else "Cannot get answer"
                    }

    async def post_async(self, shared, prep_res, exec_res):
        """æ ¹æ®å†³ç­–ç»“æœè·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹"""
        # å¤„ç† exec_res ä¸ºç©ºçš„æƒ…å†µ
        if exec_res is None:
            print("\n[WARN] Decision failed, try direct answer")
            exec_res = {
                "action": Action.ANSWER,
                "reason": "Decision returned empty",
                "answer": "Sorry, processing error, please retry."
            }

        # ç¡®ä¿ exec_res æ˜¯å­—å…¸
        if not isinstance(exec_res, dict):
            exec_res = {
                "action": Action.ANSWER,
                "reason": "Decision format error",
                "answer": str(exec_res)
            }

        action = exec_res.get("action", "answer")
        reason = exec_res.get("reason", "")

        step = shared.get("step_count", 0)
        print(f"\n[Step {step}]: {action.upper()}")
        if reason:
            print(f"   Reason: {reason}")

        # è®°å½•å†³ç­–åˆ°æ—¥å¿—
        log_decision(action, reason)

        # ä¿å­˜å†³ç­–åˆ° shared
        shared["current_decision"] = exec_res

        if action == Action.TOOL:
            return Action.TOOL
        elif action == Action.THINK:
            return Action.THINK
        else:
            return Action.ANSWER
